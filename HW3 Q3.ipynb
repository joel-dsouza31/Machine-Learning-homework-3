{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Activation Function in Neural Networks\n",
    "<p>Consider a three-layer fully-connected network with D input features, one hidden layer with M\n",
    "nodes, and one output layer. The activation function of each node is a sigmoid function of the\n",
    "form</p>\n",
    "<p>sigmoid(α) = 1/\n",
    "(1 + exp(−α))</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Provide a schematic representation of the network. Define the variables for the input, the\n",
    "output, and the weights.\n",
    "\n",
    "<img src=\"q3a.JPG\" alt=\"3a\" align=\"left\" width = \"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_shape=784 #can be changed accordingly\n",
    "output_shape=1\n",
    "inp=np.random.rand(input_shape,1)\n",
    "hidden_layer_shape=(input_shape,output_shape)\n",
    "weights=np.random.rand(input_shape,output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Express the output as a function of the input.\n",
    "<br><img src=\"q3b.JPG\" alt=\"3b\" align=\"left\" width = \"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(alpha):\n",
    "    return 1/(1+np.exp(-alpha))\n",
    "\n",
    "bias=np.ones((output_shape))\n",
    "#bias=1\n",
    "output=sigmoid(np.dot(weights.T,inp)+bias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Calculate the number of parameters that need to be inferred.\n",
    "\n",
    "<img src=\"q3c.JPG\" alt=\"3c\" align=\"left\" width = \"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "parameters = input_shape * output_shape\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of parameters to be inferred will be the product of input nodes and number of nodes in hidden layer as it is a fully connected layer so each input is connected with each node in the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Show that there exists an equivalent network with hidden unit activation functions given\n",
    "by the hyperbolic tangent, which computes exactly the same function, where the hyperbolic\n",
    "tangent is given by\n",
    "tanh(α) = exp(α) − exp(−α)/\n",
    "exp(α) + exp(−α)\n",
    "Hint: First find the relation between sigmoid(α) and tanh(α), then show that the parameters\n",
    "of the two networks differ by linear transformations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Answer:</u></b>\n",
    "<br><img src=\"q3d.JPG\" alt=\"3d\" align=\"left\" width = \"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(alpha):\n",
    "    return (np.exp(alpha)-np.exp(-alpha))/(np.exp(alpha)+np.exp(-alpha))\n",
    "\n",
    "output1=sigmoid(np.dot(weights.T,inp)+bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
