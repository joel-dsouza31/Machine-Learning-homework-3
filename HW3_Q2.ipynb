{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Gradient Descent Boosting: Hastie et al. algorithm 10.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  Oldpeak  \\\n",
      "0   63    1       typical     145   233    1        2    150      0      2.3   \n",
      "1   67    1  asymptomatic     160   286    0        2    108      1      1.5   \n",
      "2   67    1  asymptomatic     120   229    0        2    129      1      2.6   \n",
      "3   37    1    nonanginal     130   250    0        0    187      0      3.5   \n",
      "4   41    0    nontypical     130   204    0        2    172      0      1.4   \n",
      "\n",
      "   Slope   Ca        Thal  AHD  \n",
      "0      3  0.0       fixed   No  \n",
      "1      2  3.0      normal  Yes  \n",
      "2      2  2.0  reversable  Yes  \n",
      "3      3  0.0      normal   No  \n",
      "4      1  0.0      normal   No  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Heart.csv\")\n",
    "data.dropna(inplace=True)\n",
    "data.drop(columns=\"Unnamed: 0\",inplace=True)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fixed' 'normal' 'reversable']\n",
      " [18 164 115]]\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray(data)\n",
    "unique, counts = np.unique(data[\"Thal\"], return_counts=True)\n",
    "print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-4fd53cab2041>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mY1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mY1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mY1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"N_fixed\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"N_normal\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"N_reversable\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Y_fixed\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Y_normal\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Y_reversable\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X = data.iloc[:,data.columns!=\"AHD\"]\n",
    "X = X.iloc[:,X.columns!=\"Thal\"]\n",
    "Y  = data.iloc[:,-2:]\n",
    "\n",
    "dictionary = {\"nonanginal\":0,\"asymptomatic\":1,\"typical\":2,\"nontypical\":3}\n",
    "X = X.replace(dictionary)\n",
    "label=[]\n",
    "\n",
    "for i,j in zip(Y[\"AHD\"].values,Y[\"Thal\"].values):\n",
    "    if i == \"No\" and j == \"fixed\":\n",
    "        label.append(0)\n",
    "    elif i == \"No\" and  j == \"normal\":\n",
    "        label.append(1)\n",
    "    elif i == \"No\" and  j == \"reversable\":\n",
    "        label.append(2)\n",
    "    elif i == \"Yes\" and j == \"fixed\":\n",
    "        label.append(3)\n",
    "    elif i == \"Yes\" and j == \"normal\":\n",
    "        label.append(4)\n",
    "    elif i == \"Yes\" and j == \"reversable\":\n",
    "        label.append(5)\n",
    "\n",
    "label = pd.DataFrame(label,columns=[\"label\"])\n",
    "\n",
    "Y1 = to_categorical(label,6)\n",
    "Y1=Y1.astype(np.uint8)\n",
    "Y1 = pd.DataFrame(Y1,columns=[\"N_fixed\",\"N_normal\",\"N_reversable\",\"Y_fixed\",\"Y_normal\",\"Y_reversable\"])\n",
    "\n",
    "Y.drop(columns=['AHD', 'Thal'])\n",
    "Y = pd.concat([label,Y1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Please implement algorithm 10.4 for multi-class gradient boosting. You must manually implement this. If you use other sources for coding help you must cite them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class Gradient_Boosting:\n",
    "    \n",
    "    n_tree=None\n",
    "    depth= None\n",
    "    tree_gamma_dictionary ={}\n",
    "    tree_dictionary={}\n",
    "    F_train_dict={}\n",
    "    F_test_dict={}\n",
    "    fearure_importance ={}\n",
    "    \n",
    "        \n",
    "    def __init__(self,n_tree,depth):\n",
    "        self.n_tree = n_tree\n",
    "        self.depth = depth\n",
    "        self.tree_gamma_dictionary ={}\n",
    "        self.tree_dictionary={}\n",
    "        self.F_train_dict={}\n",
    "        self.F_test_dict={}\n",
    "\n",
    "    def cal_feature_importance(self):\n",
    "        feature_importance = [self.tree_dictionary[tree].feature_importances_ for tree in self.tree_dictionary]\n",
    "        fm=np.mean(feature_importance,axis=0)\n",
    "        return fm\n",
    "        \n",
    "    def F_1(self,X,s):\n",
    "        if s==\"fit\":\n",
    "            if len(self.tree_dictionary)==0:\n",
    "                a= np.zeros((len(X),6)).astype(np.uint8)\n",
    "                self.F_train_dict[0]=a\n",
    "                return a\n",
    "            else:\n",
    "                i = len(self.tree_dictionary)\n",
    "                print(i)\n",
    "                b=self.F_train_dict[i-1]\n",
    "                a=[]\n",
    "                regions=self.tree_dictionary[i-1].apply(X)\n",
    "                regions = np.array(regions)\n",
    "                for j in regions:\n",
    "                    gamma = self.tree_gamma_dictionary[i-1][j]\n",
    "                    a.append(gamma)\n",
    "                a=np.array(a)\n",
    "                b=np.add(a,b)\n",
    "                self.F_train_dict[i]=b\n",
    "\n",
    "                return b\n",
    "\n",
    "        elif s==\"predict\":\n",
    "            if len(self.tree_dictionary)==0:\n",
    "                a= np.zeros((len(X),6)).astype(np.uint8)\n",
    "                self.F_test_dict[0]=a\n",
    "                return a\n",
    "            else:\n",
    "                b=np.zeros((len(X),6))\n",
    "                for i in self.tree_dictionary:\n",
    "                    a=[]\n",
    "                    regions=self.tree_dictionary[i].apply(X)\n",
    "                    for j in regions:\n",
    "                        gamma = self.tree_gamma_dictionary[i][j]\n",
    "                        a.append(gamma)\n",
    "                    b=np.add(a,b)\n",
    "\n",
    "                return b\n",
    "\n",
    "            \n",
    "    def F(self,X):\n",
    "        if len(self.tree_dictionary)==0:\n",
    "            a= np.zeros((len(X),6)).astype(np.uint8)\n",
    "            return a\n",
    "        else:\n",
    "            b=np.zeros((len(X),6))\n",
    "            for i in self.tree_dictionary:\n",
    "                a=[]\n",
    "                regions=self.tree_dictionary[i].apply(X)\n",
    "                for j in regions:\n",
    "                    gamma = self.tree_gamma_dictionary[i][j]\n",
    "                    a.append(gamma)\n",
    "                b=np.add(a,b)\n",
    "                \n",
    "\n",
    "            return b\n",
    "\n",
    "    def predict(self,X):\n",
    "\n",
    "        F_val = self.F(X)\n",
    "        predictions = self.Pk(F_val)\n",
    "\n",
    "        output = []\n",
    "        for i in predictions:\n",
    "            temp =[]\n",
    "            label = np.argmax(i)\n",
    "            for j in range(len(i)):\n",
    "                if j==label:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)      \n",
    "            output.append(temp)\n",
    "        return output\n",
    "    \n",
    "    def Pk(self,F_val):\n",
    "        output=[]\n",
    "        for row in F_val:\n",
    "            b=np.sum(np.exp(row))\n",
    "            a=np.exp(row)\n",
    "            d = a/b \n",
    "            output.append(d)\n",
    "        return output\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        \n",
    "        f_importance=np.zeros((len(X),6))\n",
    "        \n",
    "        for i in range(self.n_tree):\n",
    "\n",
    "            numerator_dict ={}\n",
    "            denominator_dict={}\n",
    "\n",
    "            F_val = self.F(X)\n",
    "            predictions = self.Pk(F_val)\n",
    "\n",
    "            \n",
    "            residuals = np.asarray(np.array(Y)-predictions)\n",
    "\n",
    "            regressor = DecisionTreeRegressor(random_state=0,max_depth=self.depth)\n",
    "            regressor.fit(X,residuals)\n",
    "            \n",
    "            X_regions = regressor.apply(X)\n",
    "\n",
    "            for j in range(len(X_regions)):\n",
    "                if X_regions[j] not in numerator_dict:\n",
    "                    numerator_dict[X_regions[j]]=residuals[j]\n",
    "                    denominator_dict[X_regions[j]]=abs(residuals[j])*(1-abs(residuals[j]))\n",
    "                else:\n",
    "                    numerator_dict[X_regions[j]]=np.add(numerator_dict[X_regions[j]],residuals[j])\n",
    "                    denominator_dict[X_regions[j]]=np.add(denominator_dict[X_regions[j]],abs(residuals[j])*(1-abs(residuals[j])))\n",
    "                    \n",
    "            temp_dict={}\n",
    "            for k in numerator_dict:\n",
    "                temp = numerator_dict[k]/denominator_dict[k]\n",
    "                temp_dict[k]=temp/6\n",
    "            \n",
    "            self.tree_gamma_dictionary[i] = temp_dict\n",
    "            self.tree_dictionary[i]=regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-eb0f425105c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradient_Boosting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#     print(a.fearure_importance[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-ef867a5ecc22>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[0mresiduals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mregressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tree_list = [50,100,150,200,250,300,350,400,500,550,600,700,800]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y.iloc[:,1:].values,random_state=40,test_size=0.2,stratify=Y.iloc[:,1:].values)\n",
    "\n",
    "GB_loss_dict = {}\n",
    "\n",
    "for i in tree_list:\n",
    "    print(i)\n",
    "    a = Gradient_Boosting(i,3)\n",
    "\n",
    "    a.fit(X_train,Y_train)\n",
    "     \n",
    "    Y_pred = a.predict(X_test)\n",
    "    \n",
    "    Loss = log_loss(Y_test,Y_pred)\n",
    "    print(Loss)\n",
    "    GB_loss_dict[i]= Loss\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Comparison of your implementation with a popular package (XGBoost, GBM, or Light\n",
    "GBM - your choice): Using the Heart dataset - develop a multi-class classification for Heart\n",
    "Disease (AHD) and Thal crossed together (this requires you to create labels based upon the\n",
    "combination of Yes/NO and Fixed, Normal, Reversable for the final two columns). Investigate\n",
    "the number of iterations needed to optimize the testing error, then make the testing error start\n",
    "to rise for your implementation and the package you choose to compare against. For multiclass\n",
    "classification - please determine what metric you will be optimizing for comparison (note that\n",
    "AUROC only works in binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9dd16b9419cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m350\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m550\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m700\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y.iloc[:,0].values,random_state=40, test_size=0.2,stratify=Y.iloc[:,0].values)\n",
    "s = [50,100,150,200,250,300,350,400,500,550,600,700,800]\n",
    "loss_dict = {}\n",
    "for i in s:\n",
    "    xgb_c = XGBClassifier(max_depth=3, n_estimators=i, n_jobs=-1)\n",
    "    xgb_c.fit(X_train, Y_train,)\n",
    "    pred   = xgb_c.predict(X_test)\n",
    "\n",
    "    pred = to_categorical(pred,6)\n",
    "    Y_test=Y_test.astype(np.uint8)\n",
    "    \n",
    "    Loss = log_loss(Y_test,pred)\n",
    "    loss_dict[i]= Loss\n",
    "\n",
    "\n",
    "plt.figure(figsize = (16,10))\n",
    "plt.scatter([tree for tree in s], [loss_dict[tree] for tree in s])\n",
    "plt.scatter([tree for tree in tree_list], [GB_loss_dict[tree] for tree in tree_list],color=\"red\")\n",
    "plt.plot([tree for tree in s], [loss_dict[tree] for tree in s])\n",
    "plt.plot([tree for tree in tree_list], [GB_loss_dict[tree] for tree in tree_list],color=\"red\")\n",
    "plt.title('Loss for XGBOOST Package')\n",
    "plt.xlabel('Trees')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Please provide your feature importance, and compare to the package choice’s feature importance. Describe similarity vs. differences and explain (in particular with relation to hyperparameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6f5824692bdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0masd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_feature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0me\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Feature Importance\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Feature Nmaes\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Feature Importance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    420\u001b[0m                                          dtype=values.dtype, copy=False)\n\u001b[0;32m    421\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "asd=a.cal_feature_importance()\n",
    "e=pd.DataFrame(asd,columns=[\"Feature Importance\"])\n",
    "f=pd.DataFrame(X_train.columns,columns=[\"Feature Nmaes\"])\n",
    "g=pd.concat([f,e],axis=1)\n",
    "g.sort_values(by=['Feature Importance'])\n",
    "\n",
    "print(\"Feature Importance of our model\")\n",
    "\n",
    "print(g)\n",
    "\n",
    "xgb_c = XGBClassifier(max_depth=3, n_estimators=800, n_jobs=-1)\n",
    "xgb_c.fit(X_train, Y_train,)\n",
    "asd = xgb_c.feature_importances_\n",
    "    \n",
    "e=pd.DataFrame(asd,columns=[\"Feature Importance\"])\n",
    "f=pd.DataFrame(X_train.columns,columns=[\"Feature Nmaes\"])\n",
    "\n",
    "g=pd.concat([f,e],axis=1)\n",
    "g.sort_values(by=['Feature Importance'])\n",
    "\n",
    "print(\"XGBoost Feature Importance\")\n",
    "\n",
    "print(g.head(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class Gradient_Boosting:\n",
    "    \n",
    "    n_tree=None\n",
    "    depth= None\n",
    "    tree_gamma_dictionary ={}\n",
    "    tree_dictionary={}\n",
    "    F_dict={}\n",
    "        \n",
    "    def __init__(self,n_tree,depth):\n",
    "        self.n_tree = n_tree\n",
    "        self.depth = depth\n",
    "        \n",
    "    def F(self,X):\n",
    "        if len(self.tree_dictionary)==0:\n",
    "            a= np.zeros((len(X),6)).astype(np.uint8)\n",
    "            return a\n",
    "        else:\n",
    "            b=np.zeros((len(X),6))\n",
    "            for i in self.tree_dictionary:\n",
    "                a=[]\n",
    "                regions=self.tree_dictionary[i].apply(X)\n",
    "                for j in regions:\n",
    "                    gamma = self.tree_gamma_dictionary[i][j]\n",
    "                    a.append(gamma)\n",
    "                b=np.add(a,b)\n",
    "            return b\n",
    "                \n",
    "    def predict(self,X):\n",
    "        F_val = self.F(X)\n",
    "        predictions = self.Pk(F_val)\n",
    "        output = []\n",
    "        for i in predictions:\n",
    "            temp =[]\n",
    "            label = np.argmax(i)\n",
    "            for j in range(len(i)):\n",
    "                if j==label:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(0)      \n",
    "            output.append(temp)\n",
    "        return output\n",
    "    \n",
    "    def Pk(self,F_val):\n",
    "        output=[]\n",
    "        for row in F_val:\n",
    "            b=np.sum(np.exp(row))\n",
    "            a=np.exp(row)\n",
    "            d = a/b \n",
    "            output.append(d)\n",
    "        return output\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        \n",
    "        for i in range(self.n_tree):\n",
    "            numerator_dict ={}\n",
    "            denominator_dict={}\n",
    "            F_val = self.F(X)\n",
    "            predictions = self.Pk(F_val)\n",
    "            residuals = np.asarray(np.array(Y)-predictions)\n",
    "            regressor = DecisionTreeRegressor(random_state=0,max_depth=self.depth)\n",
    "            regressor.fit(X,residuals)\n",
    "\n",
    "            X_regions = regressor.apply(X)\n",
    "            \n",
    "            for j in range(len(X_regions)):\n",
    "                if X_regions[j] not in numerator_dict:\n",
    "                    numerator_dict[X_regions[j]]=residuals[j]\n",
    "                    denominator_dict[X_regions[j]]=abs(residuals[j])*(1-abs(residuals[j]))\n",
    "                else:\n",
    "                    numerator_dict[X_regions[j]]+=residuals[j]\n",
    "                    denominator_dict[X_regions[j]]+=abs(residuals[j])*(1-abs(residuals[j]))\n",
    "                    \n",
    "            temp_dict={}\n",
    "            for k in numerator_dict:\n",
    "                temp_dict[k]=(numerator_dict[k]/(6*denominator_dict[k]))\n",
    "            \n",
    "            self.tree_gamma_dictionary[i] = temp_dict\n",
    "            self.tree_dictionary[i]=regressor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
